# مقارنة موديول اختبار المزادات مع قالب العميل

هذا الملف يوضح **ما هو موجود** في فرع feature/testing-autions (#149) مقابل **ما يطلبه قالب العميل**، وما الذي يمكن تصميمه أو إضافته لاحقاً.

---

## 1. الأهداف الثلاثة (القالب) vs الوضع الحالي

| الهدف من القالب | الوضع الحالي | الفجوة |
|------------------|--------------|--------|
| **توليد مزادات تجريبية بسيناريوهات متنوعة** (هادئ، متوسط، ضغط عالي، سنايبر في آخر الثواني) | ❌ لا يوجد | الموديول الحالي **لا يولد** مزادات تجريبية ولا مستخدمين افتراضيين. يكتفي بقراءة المزادات الموجودة في الـ DB والتحقق من صحتها. |
| **قياس الأداء والدقة:** من أول ضغط زر المزايدة حتى ظهور النتيجة لكل عميل | ❌ لا يوجد | يوجد فقط **وقت تنفيذ الاختبار بالكامل** (`execution_time_ms`) لكل فئة. لا يوجد قياس **زمن الاستجابة من إرسال bid حتى تأكيده في الـ backend** ولا **زمن وصول التحديث للواجهة**. |
| **إنتاج بيانات وتقارير** (logs، metrics، ملفات) | ⚠️ جزئي | النتائج تُحفظ في جدول **`auction_test_results`** (اسم الاختبار، الفئة، الحالة، الرسالة، التفاصيل، الأخطاء، وقت التنفيذ). لا يوجد جدول **auction_test_events** ولا تصدير JSON/CSV لتحليل أو AI. |

**الخلاصة:** الموديول الحالي يحقق بشكل واضح **اختبارات وظيفية** و**حفظ نتائج في DB** و**واجهة Admin**. لا يحقق **توليد سيناريوهات** ولا **قياس latency حقيقي** ولا **تقارير/ملفات قابلة للتصدير** بالشكل المطلوب في القالب.

--- 

## 2. الطبقات الأربع (القالب) vs البنية الحالية

### 2.1 طبقة تعريف السيناريوهات

| المطلوب في القالب | الموجود حالياً |
|--------------------|-----------------|
| كائن/ملف مثل `AuctionScenario` يحتوي: نوع السيناريو (SMALL_LOAD, PEAK_LOAD, SNIPER_ENDING, MULTI_AUCTION)، عدد المستخدمين، مدة المزاد، نمط توزيع الـ bids (عشوائي، تجمّع في النهاية، ثابت). ملف مركزي مثل `auctionTestScenarios.ts` | ❌ **لا يوجد** أي تعريف لسيناريوهات من هذا النوع. الفئات الحالية (logic, transitions, price_updates, state_consistency) هي **أنواع اختبارات وظيفية** وليست سيناريوهات حمل أو توزيع مزايدات. |

**ما يمكن إضافته لاحقاً (بدون تنفيذ الآن):**  
- ملف `scenarios.ts` (أو PHP) يعرّف سيناريوهات: اسم، نوع الحمل، عدد المستخدمين الافتراضيين، مدة المزاد، نمط الـ bids.  
- استخدام هذه التعريفات في طبقة الـ Runner عند إضافة «تشغيل سيناريو».

---

### 2.2 طبقة مشغّل السيناريوهات (Scenario Runner)

| المطلوب في القالب | الموجود حالياً |
|--------------------|-----------------|
| إنشاء مزادات test (مع flag مثل `isTestAuction = true`) | ❌ لا يوجد إنشاء مزادات تجريبية. |
| توليد مستخدمين test (virtual bidders) وجلسات (WebSocket/Pusher) | ❌ لا يوجد. |
| ضخ الـ bids حسب السيناريو (عشوائي، انفجار في آخر 30–60 ثانية) | ❌ لا يوجد. |
| خدمة مركزية واحدة (AuctionTestRunner) لتشغيل السيناريوهات | ✅ يوجد **AuctionTestRunner** لكنه يشغّل فقط **الاختبارات الوظيفية الأربع** (runAllTests / runTestByCategory). لا يشغّل «سيناريوهات» بالمعنى الذي في القالب. |

**الخلاصة:** الـ Runner الحالي = **مشغّل اختبارات وظيفية** (فحص منطق على بيانات موجودة). لا يوجد **مشغّل سيناريوهات** (إنشاء مزادات + bidders + ضخ bids).

---

### 2.3 طبقة القياس والمراقبة (Metrics & Logs)

| المطلوب في القالب | الموجود حالياً |
|--------------------|-----------------|
| زمن الاستجابة من إرسال bid حتى تأكيده في الـ backend | ❌ لا يُقاس. |
| زمن انتشار التحديث إلى الواجهة (front-end receive time) | ❌ لا يُقاس. |
| عدد الأخطاء: rejected bids، timeouts، sync issues | ⚠️ جزئي: الاختبارات الوظيفية تسجّل **أخطاء منطقية** في حقل `errors` في النتيجة. لا يوجد عداد لـ rejected bids أو timeouts من واجهة المزايدة. |
| تخزين في جدول `auction_test_runs` + `auction_test_events` أو ملفات JSON/CSV | ⚠️ جزئي: جدول واحد **`auction_test_results`** (نتيجة كل تشغيل لفئة واحدة). لا يوجد جدول أحداث (events) ولا تصدير ملفات. |

**ما يمكن إضافته لاحقاً:**  
- جدول `auction_test_runs` (تشغيلة سيناريو واحدة) و`auction_test_events` (كل حدث: bid أُرسل، bid تأكد، تحديث وصل للعميل، خطأ، إلخ).  
- أو حفظ نفس البيانات في ملفات JSON/CSV لتحليل لاحق.

---

### 2.4 طبقة الوصول (Access & UI)

| المطلوب في القالب | الموجود حالياً |
|--------------------|-----------------|
| واجهة Admin لتشغيل سيناريو: اختيار السيناريو من قائمة، تحديد عدد الجلسات/المستخدمين، بدء الاختبار | ⚠️ جزئي: يوجد **اختيار فئة اختبار** (logic, transitions, price_updates, state_consistency) وتشغيل الكل أو فئة واحدة. **لا يوجد** اختيار «سيناريو حمل» ولا تحديد «عدد المستخدمين/الجلسات». |
| متابعة النتائج في live dashboard (latency، errors) | ⚠️ جزئي: يوجد عرض النتائج (نجاح/فشل، رسالة، تفاصيل، أخطاء، وقت التنفيذ) وتحديث لحظي عبر Pusher. **لا يوجد** عرض latency لكل bid أو رسم بياني للأداء. |
| حماية: route خلف صلاحية أو feature flag | ✅ موجود: الصفحة والـ API خلف صلاحيات `auction_tests.*` و Admin. |

---

## 3. أنواع الاختبارات (القالب) vs الموجود

| النوع في القالب | الموجود حالياً |
|------------------|-----------------|
| **وظيفية (Functional):** أعلى bid يفوز، انتقال الحالات صح (scheduled → live → finished) | ✅ مغطى جزئياً: Logic، Transitions، StateConsistency، PriceUpdates يتحققون من صحة البيانات والمنطق والحالات على **البيانات الموجودة**. لا يوجد اختبار صريح «أعلى bid يفوز» عبر ضخ bids حقيقية. |
| **حمل (Load/Stress):** عدد كبير مستخدمين، burst في آخر دقائق | ❌ غير موجود. |
| **تكامل (Integration):** تكامل backend مع Pusher/WebSocket، خدمات خارجية | ❌ لا يوجد اختبارات تكامل من داخل الموديول. (البث يستخدم Pusher لعرض النتائج فقط.) |
| **أمنية أساسية:** bid من غير مصرح مرفوض، لا تعديل لـ bid بعد القبول | ❌ لا يوجد اختبارات أمنية داخل الموديول. |

---

## 4. الدمج مع CI/CD (القالب) vs الوضع الحالي

| المطلوب في القالب | الموجود حالياً |
|--------------------|-----------------|
| سيناريوهات رئيسية كـ test suite في CI (مثلاً GitHub Actions) | ❌ لا يوجد ربط بالـ CI. |
| سيناريو: مزاد واحد + 20–50 مزايد، سيناريو peak load قبل الإغلاق | ❌ لا يوجد مثل هذه السيناريوهات. |
| Thresholds: إذا متوسط latency فوق X يفشل الـ pipeline، إذا نسبة الأخطاء فوق X% تفشل | ❌ لا يوجد. |

---

## 5. بنية الملفات (القالب) vs البنية الحالية

| اقتراح القالب | الموجود حالياً |
|----------------|-----------------|
| `scenarios.ts` → تعريف السيناريوهات | ❌ لا يوجد. |
| `runner.ts` → تشغيل السيناريوهات وإنشاء المزادات/bidders | ⚠️ يوجد **AuctionTestRunner** (PHP) لتشغيل الاختبارات الوظيفية فقط، بدون إنشاء مزادات أو bidders. |
| `metrics.ts` → تسجيل النتائج في DB أو ملفات | ⚠️ النتائج تُحفظ في **AuctionTestResult** وجدول `auction_test_results`. لا يوجد ملف/طبقة مخصصة لـ metrics (latency، أحداث). |
| `routes.ts` → endpoints داخلية (admin only) | ✅ موجود: `backend/Modules/Test/Routes/api.php` مع صلاحيات. |
| `README.md` | ✅ موجود في الـ Backend والـ Frontend. |

---

## 6. إجابات أسئلة القالب (قسم 5)

| السؤال | الإجابة المختصرة |
|--------|-------------------|
| هل يوجد ملف/طبقة واضحة لتعريف **السيناريوهات** (حمل، توزيع bids)؟ | **لا.** السيناريوهات بالمعنى المطلوب (SMALL_LOAD, PEAK_LOAD, SNIPER_ENDING، إلخ) غير موجودة. |
| هل يوجد مشغّل واحد مركزي للسيناريوهات (Runner)؟ | **جزئياً:** يوجد Runner مركزي لكنه يشغّل **اختبارات وظيفية** فقط، وليس «سيناريوهات» بإنشاء مزادات وضخ bids. |
| هل تُجمع مؤشرات زمن وأخطاء بشكل منظم في DB أو logs قابلة للتحليل؟ | **جزئياً:** نتائج التشغيل (فئة، حالة، أخطاء، execution_time_ms) في `auction_test_results`. لا توجد أحداث تفصيلية ولا latency لكل bid. |
| هل هناك حماية قوية تمنع استخدام أدوات الاختبار من مستخدمين عاديين؟ | **نعم:** الصفحة والـ API خلف صلاحيات Admin و `auction_tests.*`. |
| هل تم ربط أي جزء من الاختبارات مع الـ CI؟ | **لا.** التشغيل يدوي من الـ Dashboard أو الـ API. |

---

## 7. الخلاصة: هل في حاجة نُصمّمها زيادة؟

- **ما تم تنفيذه فعلياً (فرع #149):**
  - موديول **اختبارات وظيفية** لمنطق المزادات (Logic، Transitions، Price Updates، State Consistency).
  - **Runner** مركزي (AuctionTestRunner) + حفظ النتائج في **auction_test_results**.
  - واجهة **Admin** (`/admin/auction-tests`) مع صلاحيات، وتحديث لحظي عبر Pusher.
  - **لا** توليد مزادات تجريبية، **لا** مستخدمين افتراضيين، **لا** ضخ bids، **لا** قياس latency، **لا** سيناريوهات حمل، **لا** CI.

- **ما يطلبه القالب زيادةً عن ذلك (بدون تنفيذ الآن، فقط كتصميم مستقبلي):**
  1. **طبقة سيناريوهات:** تعريف سيناريوهات (هادئ، متوسط، ضغط عالي، سنايبر) + عدد مستخدمين + مدة مزاد + نمط توزيع الـ bids.
  2. **مشغّل سيناريوهات:** إنشاء مزادات test (مع flag مثل `isTestAuction`)، توليد virtual bidders، ضخ bids حسب النمط (عشوائي، burst في آخر 30–60 ثانية).
  3. **طبقة metrics:** قياس زمن الاستجابة (bid → backend)، زمن وصول التحديث للعميل، عدّ الأخطاء (rejected, timeout)، وحفظ ذلك في جداول أو ملفات (auction_test_runs / auction_test_events أو JSON/CSV).
  4. **واجهة:** اختيار سيناريو من قائمة، تحديد عدد الجلسات/المستخدمين، وعرض latency وعدد الأخطاء في لوحة مباشرة.
  5. **CI/CD:** تشغيل سيناريوهات محددة في الـ pipeline مع thresholds (latency، نسبة أخطاء).

يمكن استخدام هذا الملف كمرجع عند مراجعة الفرع مع العميل أو الفريق: ما الذي تحققه #149 اليوم (اختبارات وظيفية + Runner + نتائج + Admin)، وما الذي يبقى «تصميم إضافي» حسب القالب إذا أردتم الوصول لمستوى «موديول اختبار مزادات رسمي» بالكامل.
